Polynomial Regression (Machine Learning Assignment)
Overview

This repository contains a simple implementation of Polynomial Regression using Python. The project demonstrates how nonlinear relationships can be modeled by transforming input features into polynomial terms and solving the regression using Ordinary Least Squares (OLS). The implementation is designed for educational purposes as part of a Machine Learning course assignment.

Method

Given input data points x and target values y, the model constructs a polynomial design matrix:

X = [1, x, x², …, xᵈ]

The regression coefficients are computed using the closed-form OLS solution:

β = (XᵀX)⁻¹Xᵀy

Predictions are generated by multiplying the design matrix with the learned coefficients.

Implementation Details

Polynomial degree: 2
Regression method: Ordinary Least Squares

Libraries used:

NumPy (matrix operations)

Matplotlib (data visualization)

The notebook constructs the polynomial design matrix, computes regression coefficients, generates predictions, and visualizes the fitted curve against the original data points.

Visualization

The output is visualized by plotting the original data points as a scatter plot and the fitted polynomial curve as a smooth line. This illustrates how polynomial regression captures nonlinear trends in data.

Files

Polynomial_Regression.ipynb – Main implementation notebook
README.md – Project description

How to Run

Open the notebook in Google Colab or Jupyter Notebook, then run all cells sequentially. The polynomial coefficients and fitted curve will be displayed.

Notes

This implementation uses a closed-form solution and does not rely on machine learning libraries such as scikit-learn. The focus of the project is on understanding the mathematical foundations of polynomial regression.

This project is licensed under the MIT License.

